# /src/xgenml/core/train_many.py
import os
import uuid
import time
import mlflow
from typing import List, Dict, Any, Optional
from datetime import datetime

from .training.data_loader import DataLoader
from .training.model_trainer import ModelTrainer
from .training.mlflow_manager import MLflowManager
from .model_catalog import (
    get_models_by_task,
    get_primary_metric,
    validate_model_name,
    check_model_requirements,
    get_available_tasks
)
from ..services.hyperparameter_optimization import HyperparameterOptimizer
from ..utils.logger_config import setup_logger
from ..utils.file_utils import TempDirectoryManager

logger = setup_logger(__name__)


def train_from_hf(
    model_id: str,
    task: str,
    # HuggingFace Í¥ÄÎ†®
    hf_repo: Optional[str] = None,
    hf_filename: Optional[str] = None,
    # /src/xgenml/core/train_many.py (Í≥ÑÏÜç)
    hf_revision: Optional[str] = None,
    # MLflow Í¥ÄÎ†®
    use_mlflow_dataset: bool = False,
    mlflow_run_id: Optional[str] = None,
    mlflow_artifact_path: str = "dataset",
    # Îç∞Ïù¥ÌÑ∞ Í¥ÄÎ†®
    target_column: Optional[str] = None,
    feature_columns: Optional[List[str]] = None,
    model_names: Optional[List[str]] = None,
    overrides: Optional[Dict[str, Dict[str, Any]]] = None,
    test_size: float = 0.2,
    val_size: float = 0.1,
    random_state: int = 42,
    use_cv: bool = False,
    cv_folds: int = 5,
    # MLflow Ïã§Ìóò Í¥ÄÎ†®
    mlflow_experiment: Optional[str] = None,
    artifact_base_uri: Optional[str] = None,
    storage_ctor_kwargs: Optional[Dict[str, Any]] = None,
    # HPO Í¥ÄÎ†®
    hpo_config: Optional[Dict[str, Any]] = None,
    # ÌÉúÏä§ÌÅ¨Î≥Ñ ÏÑ§Ï†ï
    task_config: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    """
    Ï†ÑÏ≤òÎ¶¨ ÏôÑÎ£å Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†ï / Ïó¨Îü¨ Î™®Îç∏ ÏùºÍ¥Ñ ÌïôÏäµ¬∑ÌèâÍ∞Ä¬∑Î°úÍπÖ
    
    Args:
        model_id: Î™®Îç∏ ÏãùÎ≥ÑÏûê
        task: ÌÉúÏä§ÌÅ¨ ÌÉÄÏûÖ (classification, regression, timeseries, anomaly_detection, clustering)
        hf_repo: HuggingFace Î†àÌè¨ÏßÄÌÜ†Î¶¨
        hf_filename: HuggingFace ÌååÏùºÎ™Ö
        hf_revision: HuggingFace Î¶¨ÎπÑÏ†Ñ
        use_mlflow_dataset: MLflow Îç∞Ïù¥ÌÑ∞ÏÖã ÏÇ¨Ïö© Ïó¨Î∂Ä
        mlflow_run_id: MLflow run ID (use_mlflow_dataset=TrueÏù∏ Í≤ΩÏö∞)
        mlflow_artifact_path: MLflow ÏïÑÌã∞Ìå©Ìä∏ Í≤ΩÎ°ú
        target_column: ÌÉÄÍ≤ü Ïª¨ÎüºÎ™Ö (clusteringÏùÄ ÏÑ†ÌÉùÏÇ¨Ìï≠)
        feature_columns: ÏÇ¨Ïö©Ìï† ÌîºÏ≤ò Ïª¨Îüº (NoneÏù¥Î©¥ ÏûêÎèô ÏÑ†ÌÉù)
        model_names: ÌïôÏäµÌï† Î™®Îç∏ Î™©Î°ù (NoneÏù¥Î©¥ ÌÉúÏä§ÌÅ¨Î≥Ñ Í∏∞Î≥∏ Î™®Îç∏ ÏÇ¨Ïö©)
        overrides: Î™®Îç∏Î≥Ñ ÌååÎùºÎØ∏ÌÑ∞ Ïò§Î≤ÑÎùºÏù¥Îìú
        test_size: ÌÖåÏä§Ìä∏ ÏÑ∏Ìä∏ ÎπÑÏú®
        val_size: Í≤ÄÏ¶ù ÏÑ∏Ìä∏ ÎπÑÏú®
        random_state: ÎÇúÏàò ÏãúÎìú
        use_cv: ÍµêÏ∞® Í≤ÄÏ¶ù ÏÇ¨Ïö© Ïó¨Î∂Ä
        cv_folds: ÍµêÏ∞® Í≤ÄÏ¶ù Ìè¥Îìú Ïàò
        mlflow_experiment: MLflow Ïã§ÌóòÎ™Ö
        artifact_base_uri: Ïô∏Î∂Ä Ïä§ÌÜ†Î¶¨ÏßÄ URI (ÏÑ†ÌÉùÏÇ¨Ìï≠)
        storage_ctor_kwargs: Ïä§ÌÜ†Î¶¨ÏßÄ ÏÉùÏÑ±Ïûê kwargs
        hpo_config: ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏµúÏ†ÅÌôî ÏÑ§Ï†ï
        task_config: ÌÉúÏä§ÌÅ¨Î≥Ñ ÏÑ§Ï†ï
            - timeseries: {"lookback_window": 10, "forecast_horizon": 1, "time_column": "date"}
            - anomaly_detection: {"contamination": 0.1}
            - clustering: {"n_clusters": 3}
    
    Returns:
        ÌïôÏäµ Í≤∞Í≥º ÎîïÏÖîÎÑàÎ¶¨
    """
    training_start_time = time.time()
    execution_id = f"{model_id}_{uuid.uuid4().hex[:8]}_{int(time.time())}"
    
    # ÌôòÍ≤Ω ÏÑ§Ï†ï
    USE_UNIQUE_PATHS = os.getenv("MLFLOW_USE_UNIQUE_PATHS", "true").lower() == "true"
    CLEANUP_TEMP_FILES = os.getenv("MLFLOW_CLEANUP_TEMP", "true").lower() == "true"
    temp_manager = TempDirectoryManager(cleanup_enabled=CLEANUP_TEMP_FILES)
    
    logger.info("=" * 80)
    logger.info("üöÄ Î™®Îç∏ ÌïôÏäµ ÏãúÏûë")
    logger.info("=" * 80)
    logger.info(f"üÜî Í≥†Ïú† Ïã§Ìñâ ID: {execution_id}")
    
    try:
        # ========================================
        # 1. ÌÉúÏä§ÌÅ¨ Í≤ÄÏ¶ù
        # ========================================
        available_tasks = get_available_tasks()
        if task not in available_tasks:
            raise ValueError(
                f"Unknown task: {task}\n"
                f"Available tasks: {available_tasks}"
            )
        
        logger.info(f"\nüìã ÌïôÏäµ ÏÑ§Ï†ï:")
        logger.info(f"  - Model ID: {model_id}")
        logger.info(f"  - Execution ID: {execution_id}")
        logger.info(f"  - Task: {task}")
        logger.info(f"  - Data Source: {'MLflow' if use_mlflow_dataset else 'HuggingFace'}")
        
        if use_mlflow_dataset:
            logger.info(f"  - MLflow Run ID: {mlflow_run_id}")
            logger.info(f"  - Artifact Path: {mlflow_artifact_path}")
        else:
            logger.info(f"  - HF Repo: {hf_repo}")
            logger.info(f"  - HF Filename: {hf_filename}")
            logger.info(f"  - HF Revision: {hf_revision or 'default'}")
        
        logger.info(f"  - Target Column: {target_column or 'N/A (unsupervised)'}")
        logger.info(f"  - Feature Columns: {feature_columns or 'auto (all except target)'}")
        logger.info(f"  - Test Size: {test_size}")
        logger.info(f"  - Validation Size: {val_size}")
        logger.info(f"  - Use CV: {use_cv} ({cv_folds} folds)")
        logger.info(f"  - Random State: {random_state}")
        logger.info(f"  - Use Unique Paths: {USE_UNIQUE_PATHS}")
        
        if task_config:
            logger.info(f"  - Task Config: {task_config}")
        if overrides:
            logger.info(f"  - Overrides: {overrides}")
        if hpo_config:
            logger.info(f"  - HPO Config: {hpo_config}")
        
        # ========================================
        # 2. Î™®Îç∏ Î™©Î°ù Í≤ÄÏ¶ù
        # ========================================
        if not model_names:
            # ÌÉúÏä§ÌÅ¨Î≥Ñ Í∏∞Î≥∏ Î™®Îç∏ ÏÇ¨Ïö©
            available_models = [m["name"] for m in get_models_by_task(task)]
            model_names = available_models[:3]  # ÏÉÅÏúÑ 3Í∞ú
            logger.info(f"\nÎ™®Îç∏ ÎØ∏ÏßÄÏ†ï, ÌÉúÏä§ÌÅ¨ '{task}' Í∏∞Î≥∏ Î™®Îç∏ ÏÇ¨Ïö©: {model_names}")
        
        # Î™®Îç∏ Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù Î∞è ÌïÑÏàò Ìå®ÌÇ§ÏßÄ ÌôïÏù∏
        validated_models = []
        for name in model_names:
            if not validate_model_name(task, name):
                logger.warning(f"‚ö†Ô∏è  '{name}'ÏùÄ ÌÉúÏä§ÌÅ¨ '{task}'Ïóê ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§. Í±¥ÎÑàÎúÅÎãàÎã§.")
                continue
            
            # Ìå®ÌÇ§ÏßÄ ÏöîÍµ¨ÏÇ¨Ìï≠ ÌôïÏù∏
            req_check = check_model_requirements(task, name)
            if not req_check["available"]:
                missing = req_check['missing_packages']
                logger.warning(
                    f"‚ö†Ô∏è  '{name}' ÌïÑÏöî Ìå®ÌÇ§ÏßÄ ÎàÑÎùΩ: {missing}. Í±¥ÎÑàÎúÅÎãàÎã§.\n"
                    f"    ÏÑ§Ïπò: pip install {' '.join(missing)}"
                )
                continue
            
            validated_models.append(name)
        
        if not validated_models:
            raise ValueError(
                f"ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Î™®Îç∏Ïù¥ ÏóÜÏäµÎãàÎã§.\n"
                f"ÌÉúÏä§ÌÅ¨: {task}\n"
                f"ÏöîÏ≤≠ Î™®Îç∏: {model_names}\n"
                f"ÌïÑÏöîÌïú Ìå®ÌÇ§ÏßÄÎ•º ÏÑ§ÏπòÌñàÎäîÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî."
            )
        
        model_names = validated_models
        logger.info(f"‚úÖ Í≤ÄÏ¶ùÎêú Î™®Îç∏: {model_names}")
        
        # Primary metric ÏûêÎèô ÏÑ§Ï†ï
        best_key = get_primary_metric(task)
        logger.info(f"ÌèâÍ∞Ä ÏßÄÌëú: {best_key}")
        
        # ========================================
        # 3. MLflow ÏÑ§Ï†ï
        # ========================================
        _setup_mlflow()
        
        # Ïã§Ìóò Ïù¥Î¶Ñ Î∞è MLflow Îß§ÎãàÏ†Ä ÏÉùÏÑ±
        experiment_name = _get_experiment_name(
            mlflow_experiment, model_id, execution_id, USE_UNIQUE_PATHS
        )
        mlflow_manager = MLflowManager(experiment_name)
        
        # ========================================
        # 4. Îç∞Ïù¥ÌÑ∞ Î°úÎìú
        # ========================================
        data_loader = DataLoader(task=task, task_config=task_config)
        df, data_source_info = data_loader.load_data(
            use_mlflow_dataset=use_mlflow_dataset,
            mlflow_run_id=mlflow_run_id,
            mlflow_artifact_path=mlflow_artifact_path,
            hf_repo=hf_repo,
            hf_filename=hf_filename,
            hf_revision=hf_revision
        )
        
        # ========================================
        # 5. ÌîºÏ≤ò Ï§ÄÎπÑ
        # ========================================
        X, y, feature_names, task_metadata = data_loader.prepare_features(
            df=df,
            target_column=target_column,
            feature_columns=feature_columns
        )
        
        # ========================================
        # 6. Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†
        # ========================================
        X_train, X_val, X_test, y_train, y_val, y_test = data_loader.split_data(
            X=X, y=y,
            test_size=test_size,
            val_size=val_size,
            random_state=random_state
        )
        
        # ÎùºÎ≤® Ïù∏ÏΩîÎî© Ï†ïÎ≥¥
        label_encoding_info = data_loader.get_label_encoding_info()
        
        # ========================================
        # 7. HPO ÏÑ§Ï†ï
        # ========================================
        optimizer = None
        use_hpo = hpo_config and hpo_config.get('enable_hpo', False)
        if use_hpo:
            logger.info("\nüéØ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏµúÏ†ÅÌôî ÌôúÏÑ±Ìôî")
            optimizer = HyperparameterOptimizer(
                n_trials=hpo_config.get('n_trials', 50),
                timeout=hpo_config.get('timeout_minutes', None) * 60 
                    if hpo_config.get('timeout_minutes') else None
            )
            logger.info(f"  - Trials: {hpo_config.get('n_trials', 50)}")
            if hpo_config.get('timeout_minutes'):
                logger.info(f"  - Timeout: {hpo_config.get('timeout_minutes')} minutes")
        
        # ========================================
        # 8. Î™®Îç∏ ÌïôÏäµ
        # ========================================
        trainer = ModelTrainer(task, mlflow_manager, USE_UNIQUE_PATHS)
        if optimizer:
            trainer.set_optimizer(optimizer)
        
        results = []
        best = None
        best_score = -1e18 if task == "regression" else -1.0
        
        logger.info(f"\nü§ñ Î™®Îç∏ ÌïôÏäµ ÏãúÏûë ({len(model_names)}Í∞ú Î™®Îç∏)")
        logger.info(f"ÌèâÍ∞Ä ÏßÄÌëú: {best_key}")
        
        for idx, name in enumerate(model_names, 1):
            logger.info(f"\n{'=' * 60}")
            logger.info(f"[{idx}/{len(model_names)}] {name} ÌïôÏäµ Ï§ë...")
            logger.info(f"{'=' * 60}")
            
            try:
                summary = trainer.train_model(
                    model_name=name,
                    X_train=X_train, y_train=y_train,
                    X_val=X_val, y_val=y_val,
                    X_test=X_test, y_test=y_test,
                    execution_id=execution_id,
                    data_source_info=data_source_info,
                    label_encoding_info=label_encoding_info,
                    use_cv=use_cv,
                    cv_folds=cv_folds,
                    overrides=overrides,
                    hpo_config=hpo_config
                )
                
                results.append(summary)
                
                # Î≤†Ïä§Ìä∏ Î™®Îç∏ ÏóÖÎç∞Ïù¥Ìä∏
                score = summary["metrics"]["test"][best_key]
                if score > best_score:
                    best_score = score
                    best = summary
                    hpo_info = f" (HPO)" if summary.get("hpo_used") else ""
                    logger.info(f"üèÜ ÏÉàÎ°úÏö¥ Î≤†Ïä§Ìä∏ Î™®Îç∏: {name}{hpo_info} ({best_key}={score:.4f})")
                
            except Exception as e:
                logger.error(f"‚ùå {name} Î™®Îç∏ ÌïôÏäµ Ïã§Ìå®: {str(e)}")
                import traceback
                logger.error(traceback.format_exc())
                continue
        
        # ========================================
        # 9. Í≤∞Í≥º Í≤ÄÏ¶ù
        # ========================================
        if not best:
            raise RuntimeError("Î™®Îì† Î™®Îç∏ ÌïôÏäµÏù¥ Ïã§Ìå®ÌñàÏäµÎãàÎã§")
        
        hpo_info = f" (HPO)" if best.get("hpo_used") else ""
        logger.info(f"\n{'=' * 80}")
        logger.info(f"üèÜ ÏµúÍ≥† ÏÑ±Îä• Î™®Îç∏: {best['algorithm']}{hpo_info}")
        logger.info(f"Run ID: {best['run_id']}")
        logger.info(f"ÏµúÍ≥† {best_key}: {best_score:.4f}")
        logger.info(f"{'=' * 80}")
        
        if best.get("hpo_used") and best.get("hpo_results"):
            logger.info(f"HPO ÏµúÏ†Å ÌååÎùºÎØ∏ÌÑ∞: {best['final_params']}")
        
        # ========================================
        # 10. Manifest ÏÉùÏÑ± Î∞è Ï†ÄÏû•
        # ========================================
        manifest = _create_manifest(
            results=results,
            best=best,
            feature_names=feature_names,
            model_id=model_id,
            execution_id=execution_id,
            task=task,
            training_start_time=training_start_time,
            data_source_info=data_source_info,
            use_hpo=use_hpo,
            hpo_config=hpo_config,
            label_encoding_info=label_encoding_info,
            task_metadata=task_metadata,
            USE_UNIQUE_PATHS=USE_UNIQUE_PATHS,
            CLEANUP_TEMP_FILES=CLEANUP_TEMP_FILES
        )
        
        mlflow_manager.save_manifest(manifest, best["run_id"])
        
        # ========================================
        # 11. Model Registry Îì±Î°ù
        # ========================================
        production_version = None
        version_tags = {}
        
        if os.getenv("ENABLE_MODEL_REGISTRY", "true").lower() == "true" and best.get("model_saved", False):
            version_tags = _create_version_tags(
                execution_id=execution_id,
                data_source_info=data_source_info,
                use_mlflow_dataset=use_mlflow_dataset,
                mlflow_run_id=mlflow_run_id,
                hf_repo=hf_repo,
                best=best,
                label_encoding_info=label_encoding_info,
                task_metadata=task_metadata,
                USE_UNIQUE_PATHS=USE_UNIQUE_PATHS
            )
            
            production_version = mlflow_manager.register_best_model(
                model_name=model_id,
                best=best,
                feature_names=feature_names,
                version_tags=version_tags
            )
        elif not best.get("model_saved", False):
            logger.warning("‚ö†Ô∏è  Î≤†Ïä§Ìä∏ Î™®Îç∏Ïùò ÏïÑÌã∞Ìå©Ìä∏Í∞Ä Ï†ÄÏû•ÎêòÏßÄ ÏïäÏïÑ Model Registry Îì±Î°ùÏùÑ Í±¥ÎÑàÎúÅÎãàÎã§")
        else:
            logger.info("‚ÑπÔ∏è  Model Registry ÎπÑÌôúÏÑ±ÌôîÎê® (ENABLE_MODEL_REGISTRY=false)")
        
        # ========================================
        # 12. ÌïôÏäµ ÏôÑÎ£å ÏöîÏïΩ
        # ========================================
        _log_training_summary(
            execution_id=execution_id,
            num_results=len(results),
            best=best,
            data_source_info=data_source_info,
            use_hpo=use_hpo,
            results=results,
            label_encoding_info=label_encoding_info,
            production_version=production_version,
            model_id=model_id,
            training_start_time=training_start_time,
            task=task,
            task_metadata=task_metadata
        )
        
        # ========================================
        # 13. Î∞òÌôò Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±
        # ========================================
        return _create_return_data(
            results=results,
            best=best,
            execution_id=execution_id,
            model_id=model_id,
            production_version=production_version,
            version_tags=version_tags,
            training_start_time=training_start_time,
            feature_names=feature_names,
            data_source_info=data_source_info,
            use_hpo=use_hpo,
            hpo_config=hpo_config,
            label_encoding_info=label_encoding_info,
            task_metadata=task_metadata,
            USE_UNIQUE_PATHS=USE_UNIQUE_PATHS,
            CLEANUP_TEMP_FILES=CLEANUP_TEMP_FILES,
            task=task
        )
        
    except Exception as e:
        total_duration = time.time() - training_start_time
        logger.error(f"\n{'=' * 80}")
        logger.error(f"üí• ÌïôÏäµ Ïã§Ìå®! ({total_duration:.2f}Ï¥à)")
        logger.error(f"{'=' * 80}")
        logger.error(f"Ïã§Ìñâ ID: {execution_id}")
        logger.error(f"ÏóêÎü¨: {str(e)}")
        logger.error(f"ÏóêÎü¨ ÌÉÄÏûÖ: {type(e).__name__}")
        import traceback
        logger.error(f"Ï†ÑÏ≤¥ Ïä§ÌÉùÌä∏Î†àÏù¥Ïä§:\n{traceback.format_exc()}")
        logger.error(f"{'=' * 80}")
        raise
    
    finally:
        # ÏûÑÏãú ÎîîÎ†âÌÜ†Î¶¨ Ï†ïÎ¶¨
        temp_manager.cleanup()


# ============================================================================
# Helper Functions
# ============================================================================

def _setup_mlflow():
    """MLflow Í∏∞Î≥∏ ÏÑ§Ï†ï"""
    logger.info("\nüîß MLflow ÏÑ§Ï†ï Ï§ë...")
    tracking_uri = os.getenv("MLFLOW_TRACKING_URI", "")
    if not tracking_uri:
        logger.warning("‚ö†Ô∏è  MLFLOW_TRACKING_URI ÌôòÍ≤ΩÎ≥ÄÏàòÍ∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏùå")
        raise ValueError("MLFLOW_TRACKING_URI ÌôòÍ≤ΩÎ≥ÄÏàòÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§")
    
    logger.info(f"MLflow Tracking URI: {tracking_uri}")
    mlflow.set_tracking_uri(tracking_uri)
    
    artifact_root = os.getenv("MLFLOW_DEFAULT_ARTIFACT_ROOT", "s3://mlflow-artifacts")
    s3_endpoint = os.getenv("MLFLOW_S3_ENDPOINT_URL")
    
    logger.info(f"Artifact Root: {artifact_root}")
    if s3_endpoint:
        logger.info(f"S3 Endpoint (MinIO): {s3_endpoint}")
    
    logger.info("‚úÖ MLflow ÏÑ§Ï†ï ÏôÑÎ£å")


def _get_experiment_name(
    mlflow_experiment: Optional[str],
    model_id: str,
    execution_id: str,
    use_unique_paths: bool
) -> str:
    """Ïã§Ìóò Ïù¥Î¶Ñ ÏÉùÏÑ±"""
    if use_unique_paths:
        return mlflow_experiment or f"model_{execution_id}"
    else:
        return mlflow_experiment or f"model_{model_id}"


def _create_manifest(
    results, best, feature_names, model_id, execution_id, task,
    training_start_time, data_source_info, use_hpo, hpo_config,
    label_encoding_info, task_metadata, USE_UNIQUE_PATHS, CLEANUP_TEMP_FILES
) -> Dict[str, Any]:
    """Manifest ÏÉùÏÑ±"""
    logger.info("\nüìÑ Manifest ÏÉùÏÑ± Ï§ë...")
    
    # JSON ÏßÅÎ†¨Ìôî Í∞ÄÎä•ÌïòÎèÑÎ°ù Ï≤òÎ¶¨
    serializable_results = []
    for result in results:
        result_copy = result.copy()
        if result_copy.get('hpo_results'):
            hpo_copy = result_copy['hpo_results'].copy()
            hpo_copy.pop('study', None)  # Optuna Study Í∞ùÏ≤¥ Ï†úÍ±∞
            result_copy['hpo_results'] = hpo_copy
        serializable_results.append(result_copy)
    
    best_copy = best.copy()
    if best_copy.get('hpo_results'):
        hpo_copy = best_copy['hpo_results'].copy()
        hpo_copy.pop('study', None)
        best_copy['hpo_results'] = hpo_copy
    
    manifest = {
        "results": serializable_results,
        "best": best_copy,
        "feature_names": feature_names,
        "model_id": model_id,
        "execution_id": execution_id,
        "task": task,
        "training_timestamp": datetime.now().isoformat(),
        "training_duration": time.time() - training_start_time,
        "data_source": data_source_info,
        "hpo_summary": {
            "enabled": use_hpo,
            "models_optimized": sum(1 for r in results if r.get("hpo_used", False)) if use_hpo else 0,
            "config": hpo_config if use_hpo else None
        },
        "label_encoding": label_encoding_info,
        "task_metadata": task_metadata,
        "version_info": {
            "unique_execution": USE_UNIQUE_PATHS,
            "cleanup_enabled": CLEANUP_TEMP_FILES,
        }
    }
    
    return manifest


def _create_version_tags(
    execution_id, data_source_info, use_mlflow_dataset,
    mlflow_run_id, hf_repo, best, label_encoding_info,
    task_metadata, USE_UNIQUE_PATHS
) -> Dict[str, str]:
    """Î™®Îç∏ Î≤ÑÏ†Ñ ÌÉúÍ∑∏ ÏÉùÏÑ±"""
    version_tags = {
        "execution_id": execution_id,
        "training_timestamp": datetime.now().isoformat(),
        "data_source": data_source_info["source_type"],
        "unique_run": str(USE_UNIQUE_PATHS),
    }
    
    if use_mlflow_dataset:
        version_tags["source_mlflow_run_id"] = mlflow_run_id
    else:
        version_tags["source_hf_repo"] = hf_repo
    
    if best.get("hpo_used"):
        version_tags["hpo_optimized"] = "true"
        version_tags["hpo_trials"] = str(best.get("hpo_results", {}).get("n_trials", 0))
    
    if label_encoding_info and label_encoding_info.get("used"):
        version_tags["label_encoded"] = "true"
        version_tags["num_classes"] = str(len(label_encoding_info.get("original_classes", [])))
    
    # ÌÉúÏä§ÌÅ¨ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
    if task_metadata:
        for key, value in task_metadata.items():
            if key not in ["encoder", "label_mapping"]:  # ÏßÅÎ†¨Ìôî Î∂àÍ∞Ä Í∞ùÏ≤¥ Ï†úÏô∏
                version_tags[f"task_{key}"] = str(value)
    
    return version_tags


def _log_training_summary(
    execution_id, num_results, best, data_source_info,
    use_hpo, results, label_encoding_info, production_version,
    model_id, training_start_time, task, task_metadata
):
    """ÌïôÏäµ ÏôÑÎ£å ÏöîÏïΩ Î°úÍπÖ"""
    total_duration = time.time() - training_start_time
    
    logger.info(f"\n{'=' * 80}")
    logger.info(f"üéâ Ï†ÑÏ≤¥ ÌïôÏäµ ÏôÑÎ£å! ({total_duration:.2f}Ï¥à)")
    logger.info(f"{'=' * 80}")
    logger.info(f"Ïã§Ìñâ ID: {execution_id}")
    logger.info(f"ÌÉúÏä§ÌÅ¨: {task}")
    logger.info(f"ÌïôÏäµÎêú Î™®Îç∏ Ïàò: {num_results}")
    logger.info(f"Î≤†Ïä§Ìä∏ Î™®Îç∏: {best['algorithm']}")
    logger.info(f"Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§: {data_source_info['source_type']}")
    
    if use_hpo:
        hpo_count = sum(1 for r in results if r.get("hpo_used", False))
        logger.info(f"HPO Ï†ÅÏö©Îêú Î™®Îç∏ Ïàò: {hpo_count}/{num_results}")
    
    if label_encoding_info and label_encoding_info.get("used"):
        original_classes = label_encoding_info.get("original_classes", [])
        logger.info(f"ÎùºÎ≤® Ïù∏ÏΩîÎî© Ï†ÅÏö©: {original_classes} -> {list(range(len(original_classes)))}")
    
    # ÌÉúÏä§ÌÅ¨Î≥Ñ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Î°úÍπÖ
    if task == "timeseries":
        logger.info(f"ÏãúÍ≥ÑÏó¥ ÏÑ§Ï†ï: lookback={task_metadata.get('lookback_window')}, "
                   f"horizon={task_metadata.get('forecast_horizon')}")
    elif task == "anomaly_detection":
        logger.info(f"Ïù¥ÏÉÅ ÌÉêÏßÄ Î™®Îìú: {'ÏßÄÎèÑ' if task_metadata.get('is_supervised') else 'ÎπÑÏßÄÎèÑ'}")
        logger.info(f"Contamination: {task_metadata.get('contamination')}")
    elif task == "clustering":
        logger.info(f"Î™©Ìëú ÌÅ¥Îü¨Ïä§ÌÑ∞ Ïàò: {task_metadata.get('n_clusters')}")
    
    if production_version:
        logger.info(f"Model Registry: {model_id} v{production_version} (Production)")
    
    logger.info(f"{'=' * 80}")


def _create_return_data(
    results, best, execution_id, model_id, production_version,
    version_tags, training_start_time, feature_names,
    data_source_info, use_hpo, hpo_config, label_encoding_info,
    task_metadata, USE_UNIQUE_PATHS, CLEANUP_TEMP_FILES, task
) -> Dict[str, Any]:
    """Î∞òÌôò Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±"""
    return {
        "results": results,
        "best": best,
        "execution_id": execution_id,
        "runs_manifest_uri": "",
        "registry": {
            "model_name": model_id,
            "production_version": production_version or "",
            "version_tags": version_tags if production_version else {}
        },
        "training_duration": time.time() - training_start_time,
        "feature_names": feature_names,
        "training_timestamp": datetime.now().isoformat(),
        "data_source": data_source_info,
        "task": task,
        "task_metadata": task_metadata,
        "hpo_summary": {
            "enabled": use_hpo,
            "models_optimized": sum(1 for r in results if r.get("hpo_used", False)) if use_hpo else 0,
            "config": hpo_config if use_hpo else None
        },
        "label_encoding": label_encoding_info,
        "version_info": {
            "unique_execution": USE_UNIQUE_PATHS,
            "cleanup_enabled": CLEANUP_TEMP_FILES,
        }
    }
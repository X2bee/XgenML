# /src/xgenml/core/training/model_trainer.py
import time
import tempfile
import pandas as pd
from pathlib import Path
from typing import Dict, Any, Optional, Tuple

from src.xgenml.core.model_provider import create_estimator, UserScriptModel
from src.xgenml.services.hyperparameter_optimization import HyperparameterOptimizer
from src.xgenml.core.training.evaluator import ModelEvaluator
from src.xgenml.core.training.mlflow_manager import MLflowManager
from src.xgenml.utils.logger_config import setup_logger
from src.xgenml.services.script_executor import ScriptExecutor

logger = setup_logger(__name__)


class ModelTrainer:
    """ê°œë³„ ëª¨ë¸ í•™ìŠµ ë‹´ë‹¹ í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        task: str,
        mlflow_manager: MLflowManager,
        use_unique_paths: bool = True
    ):
        self.task = task
        self.mlflow_manager = mlflow_manager
        self.use_unique_paths = use_unique_paths
        self.evaluator = ModelEvaluator(task)
        self.optimizer: Optional[HyperparameterOptimizer] = None
    
    def set_optimizer(self, optimizer: HyperparameterOptimizer):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ì˜µí‹°ë§ˆì´ì € ì„¤ì •"""
        self.optimizer = optimizer
    
    def train_model(
        self,
        model_name: str,
        X_train, y_train,
        X_val, y_val,
        X_test, y_test,
        execution_id: str,
        data_source_info: Dict[str, Any],
        label_encoding_info: Optional[Dict[str, Any]] = None,
        use_cv: bool = False,
        cv_folds: int = 5,
        overrides: Optional[Dict[str, Any]] = None,
        hpo_config: Optional[Dict[str, Any]] = None,
        input_schema: Optional[Dict[str, Any]] = None,  # NEW
        output_schema: Optional[Dict[str, Any]] = None  # NEW
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ"""
        model_start_time = time.time()
        logger.info(f"\n{model_name} í•™ìŠµ ì¤‘...")
        
        try:
            # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¤€ë¹„
            model_params, hpo_results = self._prepare_model_params(
                model_name, X_train, y_train, X_val, y_val,
                cv_folds, overrides, hpo_config
            )
            
            # ëª¨ë¸ ìƒì„±
            logger.info("ëª¨ë¸ ìƒì„± ì¤‘...")
            estimator = create_estimator(self.task, model_name, model_params)
            logger.info(f"ëª¨ë¸ ìƒì„± ì™„ë£Œ: {type(estimator).__name__}")

            if isinstance(estimator, UserScriptModel):
                # User Script Execution
                logger.info("ì‚¬ìš©ì ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰...")
                script_executor = ScriptExecutor()
                with tempfile.TemporaryDirectory() as temp_dir:
                    temp_path = Path(temp_dir)
                    artifact_dir = temp_path / "artifacts"
                    artifact_dir.mkdir(parents=True, exist_ok=True)

                    X_train_path = temp_path / "X_train.parquet"
                    y_train_path = temp_path / "y_train.parquet"
                    X_val_path = temp_path / "X_val.parquet"
                    y_val_path = temp_path / "y_val.parquet"
                    X_test_path = temp_path / "X_test.parquet"
                    y_test_path = temp_path / "y_test.parquet"

                    X_train.to_parquet(X_train_path)
                    pd.Series(y_train).to_frame().to_parquet(y_train_path)
                    X_val.to_parquet(X_val_path)
                    pd.Series(y_val).to_frame().to_parquet(y_val_path)
                    X_test.to_parquet(X_test_path)
                    pd.Series(y_test).to_frame().to_parquet(y_test_path)

                    run_config = {
                        "X_train_path": str(X_train_path),
                        "y_train_path": str(y_train_path),
                        "X_val_path": str(X_val_path),
                        "y_val_path": str(y_val_path),
                        "X_test_path": str(X_test_path),
                        "y_test_path": str(y_test_path),
                        "artifact_dir": str(artifact_dir),
                        "params": model_params
                    }
                    execution_result = script_executor.execute(estimator.model_info['content'], run_config)

                # ì‹¤í–‰ ê²°ê³¼ í™•ì¸
                logger.info(f"UserScript ì‹¤í–‰ ê²°ê³¼ í‚¤: {execution_result.keys()}")
                logger.info(f"UserScript ì „ì²´ ì‹¤í–‰ ê²°ê³¼: {execution_result}")

                result_data = execution_result.get("result") or {}
                raw_metrics = result_data.get("metrics", {})
                artifacts = result_data.get("artifacts", [])

                # stdout/stderr ë¡œê¹…
                stdout = execution_result.get("stdout", [])
                stderr = execution_result.get("stderr", [])
                exit_code = execution_result.get("exit_code", -1)

                # í•­ìƒ stdout/stderr ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                logger.info("=" * 80)
                logger.info("UserScript stdout:")
                if stdout:
                    for line in stdout:
                        logger.info(f"  {line}")
                else:
                    logger.info("  (ë¹„ì–´ìˆìŒ)")

                logger.warning("UserScript stderr:")
                if stderr:
                    for line in stderr:
                        logger.warning(f"  {line}")
                else:
                    logger.warning("  (ë¹„ì–´ìˆìŒ)")

                logger.info(f"UserScript exit code: {exit_code}")
                logger.info("=" * 80)

                # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ
                if exit_code != 0:
                    # stderrì™€ stdout ëª¨ë‘ í™•ì¸
                    error_lines = []
                    if stderr:
                        error_lines.extend(stderr)
                    if stdout and not stderr:
                        # stderrê°€ ë¹„ì–´ìˆìœ¼ë©´ stdoutë„ í™•ì¸
                        error_lines.extend(stdout)

                    error_msg = "\n".join(error_lines) if error_lines else f"ì‹¤í–‰ ì‹¤íŒ¨ (ìƒì„¸ ì •ë³´ ì—†ìŒ). execution_result: {execution_result}"
                    raise RuntimeError(f"UserScript ì‹¤í–‰ ì‹¤íŒ¨ (exit_code={exit_code}):\n{error_msg}")

                if not raw_metrics:
                    logger.error("UserScriptê°€ ë©”íŠ¸ë¦­ì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
                    logger.error(f"result_data: {result_data}")
                    raise RuntimeError("UserScriptê°€ ë¹„ì–´ìˆëŠ” ë©”íŠ¸ë¦­ì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤")

                # UserScript ë©”íŠ¸ë¦­ì„ í‘œì¤€ êµ¬ì¡°ë¡œ ë³€í™˜ (train/val/test)
                # UserScriptê°€ ì§ì ‘ ë°˜í™˜í•œ ë©”íŠ¸ë¦­ì€ test ë©”íŠ¸ë¦­ìœ¼ë¡œ ê°„ì£¼
                metrics = {
                    "train": {},
                    "val": {},
                    "test": raw_metrics  # UserScript ë©”íŠ¸ë¦­ì„ testë¡œ ì‚¬ìš©
                }

                logger.info(f"âœ… UserScript ì‹¤í–‰ ì™„ë£Œ - ë©”íŠ¸ë¦­: {raw_metrics}")
                logger.info(f"âœ… UserScript ì•„í‹°íŒ©íŠ¸: {len(artifacts)}ê°œ")

                estimator_for_log = None  # No estimator object for user scripts
                user_script_artifacts = artifacts  # ì•„í‹°íŒ©íŠ¸ ì €ì¥
            else:
                # ëª¨ë¸ í•™ìŠµ
                logger.info("ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
                fit_start_time = time.time()
                estimator.fit(X_train, y_train)
                fit_duration = time.time() - fit_start_time
                logger.info(f"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ({fit_duration:.2f}ì´ˆ)")

                # ëª¨ë¸ í‰ê°€
                metrics = self.evaluator.evaluate(
                    estimator, X_train, y_train, X_val, y_val, X_test, y_test,
                    use_cv, cv_folds
                )
                estimator_for_log = estimator
                user_script_artifacts = []  # ì¼ë°˜ ëª¨ë¸ì€ ì•„í‹°íŒ©íŠ¸ ì—†ìŒ

            # MLflow ë¡œê¹…
            run_name = self._generate_run_name(model_name, execution_id)

            params_to_log = {
                "algorithm": model_name,
                "use_cv": use_cv,
                "cv_folds": cv_folds,
            }
            params_to_log.update(model_params)

            run_id, model_saved = self.mlflow_manager.log_model_training(
                    run_name=run_name,
                    estimator=estimator_for_log,
                    params=params_to_log,
                    metrics=metrics,
                    X_train=X_train,
                    y_pred_test=estimator.predict(X_test) if not isinstance(estimator, UserScriptModel) else None,
                    execution_id=execution_id,
                    data_source_info=data_source_info,
                    label_encoding_info=label_encoding_info,
                    hpo_results=hpo_results,
                    input_schema=input_schema,  # NEW
                    output_schema=output_schema,  # NEW
                    user_script_artifacts=user_script_artifacts if isinstance(estimator, UserScriptModel) else None
                )
            
            # ê²°ê³¼ ìš”ì•½
            summary = {
                "run_id": run_id,
                "algorithm": model_name,
                "metrics": metrics,
                "training_duration": time.time() - model_start_time,
                "model_saved": model_saved,
                "hpo_used": bool(hpo_results),
                "hpo_results": hpo_results,
                "final_params": model_params,
                "task": self.task,
                "execution_id": execution_id
            }
            
            model_duration = time.time() - model_start_time
            logger.info(f"âœ… {model_name} ëª¨ë¸ ì™„ë£Œ ({model_duration:.2f}ì´ˆ)")
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ {model_name} ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _prepare_model_params(
        self,
        model_name: str,
        X_train, y_train,
        X_val, y_val,
        cv_folds: int,
        overrides: Optional[Dict[str, Any]],
        hpo_config: Optional[Dict[str, Any]]
    ) -> Tuple[Dict[str, Any], Optional[Dict[str, Any]]]:
        """ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¤€ë¹„ (HPO ë˜ëŠ” ê¸°ë³¸ê°’)"""
        use_hpo = hpo_config and hpo_config.get('enable_hpo', False)
        hpo_results = None
        
        if use_hpo and self.optimizer and self.optimizer._get_default_param_space(model_name, self.task):
            logger.info(f"ğŸ¯ {model_name} í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘...")
            
            # ì‚¬ìš©ì ì •ì˜ íŒŒë¼ë¯¸í„° ê³µê°„
            custom_param_space = None
            if hpo_config.get('param_spaces') and model_name in hpo_config['param_spaces']:
                custom_param_space = hpo_config['param_spaces'][model_name]
                logger.info(f"ì‚¬ìš©ì ì •ì˜ íŒŒë¼ë¯¸í„° ê³µê°„ ì‚¬ìš©: {custom_param_space}")
            
            # HPO ì‹¤í–‰
            hpo_results = self.optimizer.optimize_model(
                model_name=model_name,
                task=self.task,
                X_train=X_train,
                y_train=y_train,
                X_val=X_val,
                y_val=y_val,
                cv_folds=cv_folds,
                param_space=custom_param_space
            )
            
            model_params = hpo_results['best_params']
            logger.info(f"âœ… HPO ì™„ë£Œ - ìµœì  íŒŒë¼ë¯¸í„°: {model_params}")
            logger.info(f"HPO ìµœê³  ì ìˆ˜: {hpo_results['best_score']:.4f}")
            
        else:
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„° + ì˜¤ë²„ë¼ì´ë“œ
            if use_hpo and not self.optimizer._get_default_param_space(model_name, self.task):
                logger.info(f"âš ï¸  {model_name}ì— ëŒ€í•œ HPO íŒŒë¼ë¯¸í„° ê³µê°„ì´ ì •ì˜ë˜ì§€ ì•ŠìŒ. ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©.")
            
            model_overrides = (overrides or {}).get(model_name, {})
            model_params = model_overrides
            if model_overrides:
                logger.info(f"ì‚¬ìš©ì ì˜¤ë²„ë¼ì´ë“œ íŒŒë¼ë¯¸í„°: {model_overrides}")
        
        return model_params, hpo_results
    
    def _generate_run_name(self, model_name: str, execution_id: str) -> str:
        """MLflow run ì´ë¦„ ìƒì„±"""
        if self.use_unique_paths:
            return f"{self.task}:{model_name}:{execution_id[-8:]}"
        else:
            return f"{self.task}:{model_name}"
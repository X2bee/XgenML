# /src/xgenml/core/training/model_trainer.py
import time
from typing import Dict, Any, Optional, Tuple

from src.xgenml.core.model_provider import create_estimator
from src.xgenml.services.hyperparameter_optimization import HyperparameterOptimizer
from src.xgenml.core.training.evaluator import ModelEvaluator
from src.xgenml.core.training.mlflow_manager import MLflowManager
from src.xgenml.utils.logger_config import setup_logger

logger = setup_logger(__name__)


class ModelTrainer:
    """ê°œë³„ ëª¨ë¸ í•™ìŠµ ë‹´ë‹¹ í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        task: str,
        mlflow_manager: MLflowManager,
        use_unique_paths: bool = True
    ):
        self.task = task
        self.mlflow_manager = mlflow_manager
        self.use_unique_paths = use_unique_paths
        self.evaluator = ModelEvaluator(task)
        self.optimizer: Optional[HyperparameterOptimizer] = None
    
    def set_optimizer(self, optimizer: HyperparameterOptimizer):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ì˜µí‹°ë§ˆì´ì € ì„¤ì •"""
        self.optimizer = optimizer
    
    def train_model(
        self,
        model_name: str,
        X_train, y_train,
        X_val, y_val,
        X_test, y_test,
        execution_id: str,
        data_source_info: Dict[str, Any],
        label_encoding_info: Optional[Dict[str, Any]] = None,
        use_cv: bool = False,
        cv_folds: int = 5,
        overrides: Optional[Dict[str, Any]] = None,
        hpo_config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ"""
        model_start_time = time.time()
        logger.info(f"\n{model_name} í•™ìŠµ ì¤‘...")
        
        try:
            # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¤€ë¹„
            model_params, hpo_results = self._prepare_model_params(
                model_name, X_train, y_train, X_val, y_val,
                cv_folds, overrides, hpo_config
            )
            
            # ëª¨ë¸ ìƒì„±
            logger.info("ëª¨ë¸ ìƒì„± ì¤‘...")
            estimator = create_estimator(self.task, model_name, model_params)
            logger.info(f"ëª¨ë¸ ìƒì„± ì™„ë£Œ: {type(estimator).__name__}")
            
            # ëª¨ë¸ í•™ìŠµ
            logger.info("ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
            fit_start_time = time.time()
            estimator.fit(X_train, y_train)
            fit_duration = time.time() - fit_start_time
            logger.info(f"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ({fit_duration:.2f}ì´ˆ)")
            
            # ëª¨ë¸ í‰ê°€
            metrics = self.evaluator.evaluate(
                estimator, X_train, y_train, X_val, y_val, X_test, y_test,
                use_cv, cv_folds
            )
            
            # MLflow ë¡œê¹…
            run_name = self._generate_run_name(model_name, execution_id)
            
            params_to_log = {
                "algorithm": model_name,
                "use_cv": use_cv,
                "cv_folds": cv_folds,
            }
            params_to_log.update(model_params)
            
            run_id, model_saved = self.mlflow_manager.log_model_training(
                run_name=run_name,
                estimator=estimator,
                params=params_to_log,
                metrics=metrics,
                X_train=X_train,
                y_pred_test=estimator.predict(X_test),
                execution_id=execution_id,
                data_source_info=data_source_info,
                label_encoding_info=label_encoding_info,
                hpo_results=hpo_results
            )
            
            # ê²°ê³¼ ìš”ì•½
            summary = {
                "run_id": run_id,
                "algorithm": model_name,
                "metrics": metrics,
                "training_duration": time.time() - model_start_time,
                "model_saved": model_saved,
                "hpo_used": bool(hpo_results),
                "hpo_results": hpo_results,
                "final_params": model_params,
                "task": self.task,
                "execution_id": execution_id
            }
            
            model_duration = time.time() - model_start_time
            logger.info(f"âœ… {model_name} ëª¨ë¸ ì™„ë£Œ ({model_duration:.2f}ì´ˆ)")
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ {model_name} ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _prepare_model_params(
        self,
        model_name: str,
        X_train, y_train,
        X_val, y_val,
        cv_folds: int,
        overrides: Optional[Dict[str, Any]],
        hpo_config: Optional[Dict[str, Any]]
    ) -> Tuple[Dict[str, Any], Optional[Dict[str, Any]]]:
        """ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¤€ë¹„ (HPO ë˜ëŠ” ê¸°ë³¸ê°’)"""
        use_hpo = hpo_config and hpo_config.get('enable_hpo', False)
        hpo_results = None
        
        if use_hpo and self.optimizer and self.optimizer._get_default_param_space(model_name, self.task):
            logger.info(f"ğŸ¯ {model_name} í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘...")
            
            # ì‚¬ìš©ì ì •ì˜ íŒŒë¼ë¯¸í„° ê³µê°„
            custom_param_space = None
            if hpo_config.get('param_spaces') and model_name in hpo_config['param_spaces']:
                custom_param_space = hpo_config['param_spaces'][model_name]
                logger.info(f"ì‚¬ìš©ì ì •ì˜ íŒŒë¼ë¯¸í„° ê³µê°„ ì‚¬ìš©: {custom_param_space}")
            
            # HPO ì‹¤í–‰
            hpo_results = self.optimizer.optimize_model(
                model_name=model_name,
                task=self.task,
                X_train=X_train,
                y_train=y_train,
                X_val=X_val,
                y_val=y_val,
                cv_folds=cv_folds,
                param_space=custom_param_space
            )
            
            model_params = hpo_results['best_params']
            logger.info(f"âœ… HPO ì™„ë£Œ - ìµœì  íŒŒë¼ë¯¸í„°: {model_params}")
            logger.info(f"HPO ìµœê³  ì ìˆ˜: {hpo_results['best_score']:.4f}")
            
        else:
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„° + ì˜¤ë²„ë¼ì´ë“œ
            if use_hpo and not self.optimizer._get_default_param_space(model_name, self.task):
                logger.info(f"âš ï¸  {model_name}ì— ëŒ€í•œ HPO íŒŒë¼ë¯¸í„° ê³µê°„ì´ ì •ì˜ë˜ì§€ ì•ŠìŒ. ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©.")
            
            model_overrides = (overrides or {}).get(model_name, {})
            model_params = model_overrides
            if model_overrides:
                logger.info(f"ì‚¬ìš©ì ì˜¤ë²„ë¼ì´ë“œ íŒŒë¼ë¯¸í„°: {model_overrides}")
        
        return model_params, hpo_results
    
    def _generate_run_name(self, model_name: str, execution_id: str) -> str:
        """MLflow run ì´ë¦„ ìƒì„±"""
        if self.use_unique_paths:
            return f"{self.task}:{model_name}:{execution_id[-8:]}"
        else:
            return f"{self.task}:{model_name}"
# /src/xgenml/core/training/mlflow_manager.py
import os
import json
import tempfile
import joblib
import traceback
from typing import Dict, Any, Optional, List
from datetime import datetime
import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient
import numpy as np
from src.xgenml.utils.logger_config import setup_logger

logger = setup_logger(__name__)

PRIMARY_METRIC = {"classification": "accuracy", "regression": "r2"}


class MLflowManager:
    """MLflow ê´€ë ¨ ì‘ì—… ë‹´ë‹¹ í´ë˜ìŠ¤"""
    
    def __init__(self, experiment_name: str, artifact_root: Optional[str] = None):
        self.experiment_name = experiment_name
        self.artifact_root = artifact_root or os.getenv(
            "MLFLOW_DEFAULT_ARTIFACT_ROOT", "s3://mlflow-artifacts"
        )
        self.client = MlflowClient()
        self._log_s3_configuration()
        self._setup_experiment()

    def _log_s3_configuration(self) -> None:
        required_keys = [
            "AWS_ACCESS_KEY_ID",
            "AWS_SECRET_ACCESS_KEY",
            "MLFLOW_S3_ENDPOINT_URL",
        ]
        missing = [key for key in required_keys if not os.environ.get(key)]
        if missing:
            logger.warning(
                "í•„ìˆ˜ MinIO í™˜ê²½ë³€ìˆ˜ê°€ ëˆ„ë½ë˜ì–´ ìˆìŠµë‹ˆë‹¤: %s", ", ".join(missing)
            )
        else:
            logger.info(
                "MLflow S3 endpoint: %s",
                os.environ.get("MLFLOW_S3_ENDPOINT_URL"),
            )
    
    def _setup_experiment(self):
        """MLflow ì‹¤í—˜ ì„¤ì •"""
        logger.info(f"\nğŸ”§ MLflow ì‹¤í—˜ ì„¤ì •: {self.experiment_name}")
        
        try:
            self.experiment_id = mlflow.create_experiment(
                self.experiment_name,
                artifact_location=f"{self.artifact_root}/{self.experiment_name}"
            )
            logger.info(f"âœ… ìƒˆ ì‹¤í—˜ ìƒì„±: {self.experiment_name}")
        except Exception:
            experiment = mlflow.get_experiment_by_name(self.experiment_name)
            self.experiment_id = experiment.experiment_id
            logger.info(f"âœ… ê¸°ì¡´ ì‹¤í—˜ ì‚¬ìš©: {self.experiment_name}")
        
        mlflow.set_experiment(experiment_id=self.experiment_id)
    
    def log_model_training(
        self,
        run_name: str,
        estimator,
        params: Dict[str, Any],
        metrics: Dict[str, Any],
        X_train,
        y_pred_test,
        execution_id: str,
        data_source_info: Dict[str, Any],
        label_encoding_info: Optional[Dict[str, Any]] = None,
        hpo_results: Optional[Dict[str, Any]] = None,
        input_schema: Optional[Dict[str, Any]] = None,
        output_schema: Optional[Dict[str, Any]] = None
    ) -> tuple[str, bool]:
        """ëª¨ë¸ í•™ìŠµ ê²°ê³¼ë¥¼ MLflowì— ë¡œê¹…"""
        import pandas as pd
        
        with mlflow.start_run(run_name=run_name):
            run_id = mlflow.active_run().info.run_id
            run_info = mlflow.active_run().info
            logger.info(f"MLflow Run ID: {run_id}")
            logger.info(f"Artifact URI: {run_info.artifact_uri}")
            
            # âœ… X_trainì„ ëª…í™•í•˜ê²Œ DataFrameìœ¼ë¡œ ë³€í™˜ (í•œ ë²ˆë§Œ)
            if input_schema and input_schema.get('feature_names'):
                if not isinstance(X_train, pd.DataFrame):
                    X_train = pd.DataFrame(X_train, columns=input_schema['feature_names'])
                    logger.info(f"âœ… X_trainì„ DataFrameìœ¼ë¡œ ë³€í™˜ (features: {len(input_schema['feature_names'])})")
                else:
                    # ì»¬ëŸ¼ëª… ì •ë ¬ í™•ì¸
                    if list(X_train.columns) != input_schema['feature_names']:
                        X_train = X_train[input_schema['feature_names']]
                        logger.info(f"âœ… X_train ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬")
            
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ë¡œê¹…
            self._log_basic_params(execution_id, data_source_info, params)
            
            # ìŠ¤í‚¤ë§ˆ ë¡œê¹… (ì•„í‹°íŒ©íŠ¸)
            if input_schema or output_schema:
                self._log_schemas(run_id, input_schema, output_schema)
            
            # ë¼ë²¨ ì¸ì½”ë”© ì •ë³´ ë¡œê¹…
            if label_encoding_info and label_encoding_info.get("used"):
                self._log_label_encoding(run_id, label_encoding_info)
            
            # HPO ì •ë³´ ë¡œê¹…
            if hpo_results:
                self._log_hpo_results(hpo_results)
            
            # ë©”íŠ¸ë¦­ ë¡œê¹…
            self._log_metrics(metrics)
            
            # âœ… ëª¨ë¸ ì €ì¥ (ì´ë¯¸ DataFrameìœ¼ë¡œ ë³€í™˜ëœ X_train ì „ë‹¬)
            model_saved = self._save_model(
                estimator=estimator,
                X_train=X_train,  # ì´ë¯¸ DataFrame
                y_pred_test=y_pred_test,
                input_schema=input_schema,
                output_schema=output_schema
            )
            
            # âœ… ëª¨ë¸ ì €ì¥ ê²€ì¦
            if model_saved:
                logger.info("âœ… ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì„±ê³µ")
                # MLmodel íŒŒì¼ ì¡´ì¬ í™•ì¸
                try:
                    self.client.download_artifacts(run_id, "model/MLmodel", "/tmp")
                    logger.info("âœ… MLmodel íŒŒì¼ í™•ì¸ë¨")
                except Exception as e:
                    logger.error(f"âŒ MLmodel íŒŒì¼ ì—†ìŒ: {e}")
                    model_saved = False
            
            return run_id, model_saved

    def _log_schemas(
    self, 
    run_id: str, 
    input_schema: Optional[Dict[str, Any]], 
    output_schema: Optional[Dict[str, Any]]
    ):
        """ì…ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ì•„í‹°íŒ©íŠ¸ë¡œë§Œ ë¡œê¹…"""
        logger.info("ğŸ“Š Input/Output ìŠ¤í‚¤ë§ˆ ë¡œê¹… ì¤‘...")
        
        if input_schema:
            schema_path = f"/tmp/{run_id}_input_schema.json"
            with open(schema_path, "w", encoding="utf-8") as f:
                json.dump(input_schema, f, ensure_ascii=False, indent=2)
            mlflow.log_artifact(schema_path, artifact_path="schema")
            os.unlink(schema_path)
            logger.info(f"  âœ“ Input schema: {input_schema.get('n_features', 0)} features")
        
        if output_schema:
            schema_path = f"/tmp/{run_id}_output_schema.json"
            with open(schema_path, "w", encoding="utf-8") as f:
                json.dump(output_schema, f, ensure_ascii=False, indent=2)
            mlflow.log_artifact(schema_path, artifact_path="schema")
            os.unlink(schema_path)
            logger.info(f"  âœ“ Output schema: {output_schema.get('type', 'unknown')}")
        
        logger.info("âœ… ìŠ¤í‚¤ë§ˆ ë¡œê¹… ì™„ë£Œ")

    def _log_basic_params(
        self, execution_id: str, data_source_info: Dict[str, Any], params: Dict[str, Any]
    ):
        """ê¸°ë³¸ íŒŒë¼ë¯¸í„° ë¡œê¹…"""
        mlflow.log_param("execution_id", execution_id)
        mlflow.log_param("data_source_type", data_source_info["source_type"])
        
        if data_source_info["source_type"] == "mlflow":
            mlflow.log_param("source_mlflow_run_id", data_source_info["mlflow_run_id"])
        else:
            mlflow.log_param("source_hf_repo", data_source_info["hf_repo"])
        
        mlflow.log_params(params)
    
    def _log_label_encoding(self, run_id: str, label_info: Dict[str, Any]):
        """ë¼ë²¨ ì¸ì½”ë”© ì •ë³´ ë¡œê¹…"""
        mlflow.log_param("label_encoded", True)
        mlflow.log_param("original_classes", json.dumps(label_info["original_classes"], ensure_ascii=False))
        mlflow.log_param("label_mapping", json.dumps(label_info["label_mapping"], ensure_ascii=False))
        
        # ë¼ë²¨ ì¸ì½”ë” ì €ì¥
        encoder_path = f"/tmp/{run_id}_label_encoder.pkl"
        joblib.dump(label_info["encoder"], encoder_path)
        mlflow.log_artifact(encoder_path, artifact_path="preprocessing")
        os.unlink(encoder_path)
        
        logger.info("ğŸ“‹ ë¼ë²¨ ì¸ì½”ë”© ì •ë³´ë¥¼ MLflowì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    
    def _log_hpo_results(self, hpo_results: Dict[str, Any]):
        """HPO ê²°ê³¼ ë¡œê¹…"""
        best_params = hpo_results.get('best_params', {})
        mlflow.log_params({f"hpo_{k}": v for k, v in best_params.items()})
        mlflow.log_metric("hpo_best_score", hpo_results.get('best_score', 0.0))
        mlflow.log_metric("hpo_n_trials", hpo_results.get('n_trials', 0))
        mlflow.log_param("hpo_enabled", True)
    
    def _log_metrics(self, metrics: Dict[str, Any]):
        """ë©”íŠ¸ë¦­ ë¡œê¹…"""
        logger.info("ë©”íŠ¸ë¦­ ë¡œê¹… ì¤‘...")
        metric_count = 0
        
        for mtype, d in metrics.items():
            for k, v in d.items():
                if isinstance(v, (int, float)):
                    mlflow.log_metric(f"{mtype}_{k}", float(v))
                    metric_count += 1
        
        logger.info(f"ë©”íŠ¸ë¦­ ë¡œê¹… ì™„ë£Œ ({metric_count}ê°œ)")
    
    def _save_model(self, estimator, X_train, y_pred_test, input_schema=None, output_schema=None):
        """ëª¨ë¸ ì €ì¥ - ë¡œì»¬ ì €ì¥ í›„ MLflow ì„œë²„ë¥¼ í†µí•´ ì—…ë¡œë“œ"""
        import mlflow  # â† ì´ê±° ì¶”ê°€!
        import mlflow.sklearn
        from mlflow.models import infer_signature
        import pandas as pd
        import numpy as np
        import tempfile
        import shutil
        import os
        
        logger.info("============================================================")
        logger.info("ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì‹œì‘")
        logger.info("============================================================")
        
        active_run = mlflow.active_run()
        if not active_run:
            logger.error("Active run ì—†ìŒ")
            return False
        
        run_id = active_run.info.run_id
        
        try:
            # Input/Output example
            input_example = X_train.iloc[:min(5, len(X_train))].copy()
            
            if hasattr(estimator, 'predict_proba') and output_schema and output_schema.get('type') == 'classification':
                output_example = estimator.predict_proba(input_example)
                logger.info(f"predict_proba ì‚¬ìš© (shape: {output_example.shape})")
            else:
                output_example = estimator.predict(input_example)
                logger.info(f"predict ì‚¬ìš© (shape: {np.array(output_example).shape})")
            
            # Signature
            signature = infer_signature(input_example, output_example)
            logger.info(f"âœ… Signature ìƒì„± ì„±ê³µ")
            logger.info(f"   Input schema: {signature.inputs}")
            logger.info(f"   Output schema: {signature.outputs}")
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ëª¨ë¸ ì €ì¥
            temp_dir = tempfile.mkdtemp()
            model_path = os.path.join(temp_dir, "model")
            
            try:
                # ë¡œì»¬ íŒŒì¼ë¡œ ì €ì¥
                mlflow.sklearn.save_model(
                    sk_model=estimator,
                    path=model_path,
                    signature=signature,
                    input_example=input_example,
                )
                
                logger.info(f"âœ… ë¡œì»¬ ì €ì¥ ì™„ë£Œ: {model_path}")
                
                # ì €ì¥ëœ íŒŒì¼ í™•ì¸
                model_files = []
                for root, dirs, files in os.walk(model_path):
                    for f in files:
                        rel_path = os.path.relpath(os.path.join(root, f), model_path)
                        model_files.append(rel_path)
                
                logger.info(f"ì €ì¥ëœ íŒŒì¼: {model_files[:5]}...")  # ì²˜ìŒ 5ê°œë§Œ ë¡œê¹…
                
                # MLflow APIë¥¼ í†µí•´ ì—…ë¡œë“œ
                logger.info("MLflow ì„œë²„ë¥¼ í†µí•´ S3 ì—…ë¡œë“œ ì¤‘...")
                mlflow.log_artifacts(model_path, artifact_path="model")
                
                logger.info("ì—…ë¡œë“œ ì™„ë£Œ, ê²€ì¦ ëŒ€ê¸° ì¤‘...")
                
                # S3 ë™ê¸°í™” ëŒ€ê¸°
                import time
                time.sleep(5)
                
                # ê²€ì¦
                artifacts = self.client.list_artifacts(run_id, "model")
                if artifacts:
                    artifact_paths = [a.path for a in artifacts]
                    logger.info(f"âœ… ì—…ë¡œë“œ ê²€ì¦ ì„±ê³µ: {artifact_paths}")
                    
                    # MLmodel íŒŒì¼ í™•ì¸
                    if any('MLmodel' in p for p in artifact_paths):
                        logger.info("âœ… MLmodel íŒŒì¼ í™•ì¸ë¨")
                        logger.info("============================================================")
                        logger.info("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
                        logger.info("============================================================")
                        return True
                    else:
                        logger.error("âŒ MLmodel íŒŒì¼ ì—†ìŒ")
                        return False
                else:
                    logger.error("âŒ ì•„í‹°íŒ©íŠ¸ ëª©ë¡ ë¹„ì–´ìˆìŒ")
                    return False
                    
            finally:
                # ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ
                shutil.rmtree(temp_dir, ignore_errors=True)
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _create_custom_signature(
    self, 
    input_example, 
    output_example, 
    input_schema, 
    output_schema
    ):
        """Custom signature ìƒì„± - MLflow Schema í˜•ì‹"""
        from mlflow.types.schema import Schema, ColSpec
        from mlflow.models.signature import ModelSignature
        import pandas as pd
        import numpy as np
        
        logger.info("ìˆ˜ë™ Signature ìƒì„± ì¤‘...")
        
        # Input Schema ìƒì„±
        if isinstance(input_example, pd.DataFrame):
            input_cols = []
            for col in input_example.columns:
                dtype = input_example[col].dtype
                mlflow_dtype = self._map_to_mlflow_dtype(str(dtype))
                input_cols.append(ColSpec(mlflow_dtype, str(col)))
            input_schema_obj = Schema(input_cols)
            logger.info(f"  Input: {len(input_cols)} columns")
        else:
            raise ValueError("input_example must be DataFrame")
        
        # Output Schema ìƒì„±
        output_array = np.array(output_example)
        if output_array.ndim == 1:
            from mlflow.types import DataType
            output_schema_obj = Schema([ColSpec(DataType.double, "prediction")])
            logger.info(f"  Output: single column (1D)")
        elif output_array.ndim == 2:
            from mlflow.types import DataType
            n_outputs = output_array.shape[1]
            output_cols = [ColSpec(DataType.double, f"output_{i}") 
                        for i in range(n_outputs)]
            output_schema_obj = Schema(output_cols)
            logger.info(f"  Output: {n_outputs} columns (2D)")
        else:
            raise ValueError(f"Unsupported output dimensions: {output_array.ndim}")
        
        return ModelSignature(inputs=input_schema_obj, outputs=output_schema_obj)


    def _map_to_mlflow_dtype(self, dtype_str):
        """Python dtypeì„ MLflow dtypeìœ¼ë¡œ ë§¤í•‘"""
        from mlflow.types import DataType
        
        mapping = {
            'int': DataType.long,
            'int64': DataType.long,
            'int32': DataType.integer,
            'float': DataType.double,
            'float64': DataType.double,
            'float32': DataType.float,
            'double': DataType.double,
            'object': DataType.string,
            'str': DataType.string,
            'string': DataType.string,
            'bool': DataType.boolean,
            'datetime64': DataType.datetime,
        }
        
        return mapping.get(dtype_str.lower(), DataType.double)

    def register_best_model(
        self,
        model_name: str,
        best: Dict[str, Any],
        feature_names: List[str],
        version_tags: Optional[Dict[str, str]] = None,
        require_signature: bool = True,
        include_schema_uri_tags: bool = True,  # âœ… ê¸°ë³¸ê°’ Trueë¡œ ë³€ê²½
    ) -> Optional[str]:
        """ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ Model Registryì— ë“±ë¡"""
        logger.info("=" * 80)
        logger.info(f"Model Registry ë“±ë¡: {model_name}")
        logger.info("=" * 80)
        
        try:
            run_id = best["run_id"]
            run = self.client.get_run(run_id)
            
            # âœ… 1. MLmodel íŒŒì¼ ì¡´ì¬ í™•ì¸
            try:
                temp_dir = tempfile.mkdtemp()
                mlmodel_path = self.client.download_artifacts(
                    run_id, "model/MLmodel", temp_dir
                )
                with open(mlmodel_path, 'r') as f:
                    mlmodel_content = f.read()
                
                logger.info("âœ… MLmodel íŒŒì¼ í™•ì¸ë¨")
                
                # âœ… 2. Signature ì¡´ì¬ í™•ì¸
                has_signature = ("signature:" in mlmodel_content and 
                            "inputs:" in mlmodel_content and 
                            "outputs:" in mlmodel_content)
                
                if not has_signature:
                    msg = "âŒ MLmodelì— ìœ íš¨í•œ signatureê°€ ì—†ìŠµë‹ˆë‹¤"
                    if require_signature:
                        logger.error(f"{msg} - ë“±ë¡ ì¤‘ë‹¨")
                        return None
                    else:
                        logger.warning(f"{msg} - ê³„ì† ì§„í–‰")
                else:
                    logger.info("âœ… Signature í™•ì¸ë¨")
                    # Signature ë‚´ìš© ë¡œê¹…
                    import yaml
                    mlmodel_dict = yaml.safe_load(mlmodel_content)
                    if 'signature' in mlmodel_dict:
                        logger.info(f"   Signature: {mlmodel_dict['signature']}")
                
                import shutil
                shutil.rmtree(temp_dir)
                
            except Exception as e:
                logger.error(f"âŒ MLmodel íŒŒì¼ í™•ì¸ ì‹¤íŒ¨: {e}")
                if require_signature:
                    return None
            
            # 3. ë“±ë¡ ëª¨ë¸ ìƒì„±/í™•ì¸
            try:
                self.client.get_registered_model(model_name)
                logger.info(f"âœ… ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©: {model_name}")
            except Exception:
                self.client.create_registered_model(
                    model_name,
                    description=f"ML model: {model_name}"
                )
                logger.info(f"âœ… ìƒˆ ëª¨ë¸ ìƒì„±: {model_name}")
            
            # 4. ëª¨ë¸ ë²„ì „ ìƒì„±
            source = f"{run.info.artifact_uri}/model"
            mv = self.client.create_model_version(
                name=model_name,
                source=source,
                run_id=run_id
            )
            logger.info(f"âœ… ëª¨ë¸ ë²„ì „ ìƒì„±: v{mv.version}")
            
            # 5. íƒœê·¸ ì„¤ì •
            self._set_model_version_tags(
                model_name=model_name,
                version=mv.version,
                best=best,
                feature_names=feature_names,
                version_tags=version_tags,
                include_schema_uri_tags=include_schema_uri_tags
            )
            
            # 6. Production ìŠ¹ê²©
            self.client.transition_model_version_stage(
                name=model_name,
                version=mv.version,
                stage="Production",
                archive_existing_versions=True
            )
            logger.info(f"ğŸ‰ Production ìŠ¹ê²© ì™„ë£Œ: v{mv.version}")
            logger.info("=" * 80)
            
            return mv.version
            
        except Exception as e:
            logger.error(f"âŒ Registry ë“±ë¡ ì‹¤íŒ¨: {e}")
            logger.error(traceback.format_exc())
            return None

    def _has_signature_in_mlmodel(self, run_id: str) -> bool:
        """í•´ë‹¹ runì˜ model/MLmodel ë‚´ë¶€ì— signature ë¸”ë¡ì´ ì¡´ì¬í•˜ëŠ”ì§€ ê°„ë‹¨ ê²€ì¦"""
        import shutil
        tmp_dir = None
        try:
            tmp_dir = tempfile.mkdtemp(prefix="mlmodel_")
            local_path = self.client.download_artifacts(run_id, "model/MLmodel", tmp_dir)
            with open(local_path, "r", encoding="utf-8") as f:
                content = f.read()
            has_sig = "signature:" in content or ("inputs:" in content and "outputs:" in content)
            logger.info(f"MLmodel signature ì¡´ì¬ ì—¬ë¶€: {has_sig}")
            return has_sig
        except Exception as e:
            logger.warning(f"MLmodel ì„œëª… í™•ì¸ ì‹¤íŒ¨(run={run_id}): {e}")
            return False
        finally:
            if tmp_dir:
                try:
                    shutil.rmtree(tmp_dir)
                except Exception:
                    pass
    
    def _set_model_version_tags(
        self,
        model_name: str,
        version: str,
        best: Dict[str, Any],
        feature_names: List[str],
        version_tags: Optional[Dict[str, str]],
        include_schema_uri_tags: bool = False,
    ):
        """ëª¨ë¸ ë²„ì „ íƒœê·¸ ì„¤ì •"""
        # Feature names ì €ì¥
        feature_names_json = json.dumps(feature_names, ensure_ascii=False)
        self.client.set_model_version_tag(
            name=model_name,
            version=version,
            key="feature_names",
            value=feature_names_json,
        )
        
        # ë²„ì „ ê´€ë¦¬ íƒœê·¸
        task = best.get("task", "classification")
        primary_metric = PRIMARY_METRIC.get(task, "accuracy")
        
        version_info_tags = {
            "created_at": datetime.now().isoformat(),
            "training_run_id": best["run_id"],
            "algorithm": best.get("algorithm", "unknown"),
            "best_metric": json.dumps({
                "name": primary_metric,
                "value": best.get("metrics", {}).get("test", {}).get(primary_metric, 0.0)
            }),
        }
        
        if version_tags:
            version_info_tags.update(version_tags)
        
        for tag_key, tag_value in version_info_tags.items():
            self.client.set_model_version_tag(
                name=model_name,
                version=version,
                key=tag_key,
                value=str(tag_value),
            )
        
        logger.info(f"âœ… íƒœê·¸ ì €ì¥ ì™„ë£Œ: {len(feature_names)}ê°œ í”¼ì²˜ + {len(version_info_tags)}ê°œ ë²„ì „ íƒœê·¸")

        if include_schema_uri_tags:
            run = self.client.get_run(best["run_id"])
            schema_uri = f"{run.info.artifact_uri}/schema"
            self.client.set_model_version_tag(
                name=model_name,
                version=version,
                key="input_schema_uri",
                value=f"{schema_uri}/input_schema.json",
            )
            self.client.set_model_version_tag(
                name=model_name,
                version=version,
                key="output_schema_uri",
                value=f"{schema_uri}/output_schema.json",
            )
            logger.info("âœ… Schema URI íƒœê·¸ ì¶”ê°€ ì™„ë£Œ")
    
    def save_manifest(
    self,
    manifest: Dict[str, Any],
    run_id: str
    ) -> bool:
        """Manifestë¥¼ MLflow ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥
        
        Args:
            manifest: ì €ì¥í•  manifest ë”•ì…”ë„ˆë¦¬
            run_id: MLflow run ID
        
        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        logger.info("ë² ìŠ¤íŠ¸ runì— manifest ì €ì¥ ì¤‘ (MinIO)...")
        tmp_manifest = None

        try:
            run = self.client.get_run(run_id)
            artifact_uri = run.info.artifact_uri
            
            # í•™ìŠµ ì‹œ ì €ì¥ëœ ì›ë³¸ ëª¨ë¸ ê²½ë¡œ
            model_dir_path = f"{artifact_uri}/model"
            manifest["best_model_s3_path"] = model_dir_path
            manifest["best_model_mlmodel_path"] = f"{model_dir_path}/MLmodel"
            
            # Model Registry ê²½ë¡œ ì•ˆë‚´ ì¶”ê°€
            manifest["model_registry_info"] = {
                "note": (
                    "Model Registry ë“±ë¡ ì‹œ MLflowê°€ ìë™ìœ¼ë¡œ models/m-{hash} ê²½ë¡œì— "
                    "ë³µì‚¬ë³¸ì„ ìƒì„±í•©ë‹ˆë‹¤. ì›ë³¸ ëª¨ë¸ì€ best_model_s3_pathì— ìˆìŠµë‹ˆë‹¤."
                ),
                "training_artifact_path": model_dir_path,
                "registry_path_pattern": f"s3://mlflow-artifacts/{manifest.get('model_id', 'model')}/models/m-{{version_hash}}/artifacts/"
            }
            
            logger.info(f"Training artifact path: {model_dir_path}")

            # ì§ë ¬í™” ë¶ˆê°€ í•­ëª© ì œê±°/ì¹˜í™˜
            sanitized = self._sanitize_for_json(manifest)

            # ì„ì‹œ íŒŒì¼ ìƒì„± ë° ì €ì¥
            tmp_manifest = tempfile.NamedTemporaryFile(
                mode='w',
                delete=False,
                suffix=".json",
                encoding='utf-8'
            )
            json.dump(sanitized, tmp_manifest, ensure_ascii=False, indent=2)
            tmp_manifest.close()
            
            # Run context ì•ˆì—ì„œ ì•„í‹°íŒ©íŠ¸ ì €ì¥
            with mlflow.start_run(run_id=run_id):
                mlflow.log_artifact(tmp_manifest.name, artifact_path="manifest")
            
            logger.info(f"Manifest ì €ì¥ ì™„ë£Œ: {model_dir_path}")
            return True

        except Exception as e:
            logger.error(f"Manifest ì €ì¥ ì‹¤íŒ¨: {e}")
            logger.error(f"ìƒì„¸:\n{traceback.format_exc()}")
            return False

        finally:
            if tmp_manifest and os.path.exists(tmp_manifest.name):
                try:
                    os.unlink(tmp_manifest.name)
                except Exception:
                    pass


    def _sanitize_for_json(self, obj: Any) -> Any:
        """JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        - dict/list/tuple ì¬ê·€ ì²˜ë¦¬
        - numpy/pandas ë“± ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜ ì‹œë„
        - ì§ë ¬í™” ë¶ˆê°€ ê°ì²´ëŠ” ë¬¸ìì—´(repr)ë¡œ ì¹˜í™˜
        - íŠ¹ìˆ˜ í‚¤ ì²˜ë¦¬: 'encoder' í‚¤ëŠ” ì œê±°(ì•„í‹°íŒ©íŠ¸ë¡œ ë³„ë„ ì €ì¥ë¨)
        """
        import numpy as np
        import pandas as pd
        from sklearn.preprocessing import LabelEncoder

        # encoder ë¼ë²¨ì€ ì œê±°
        if isinstance(obj, dict):
            out = {}
            for k, v in obj.items():
                if k in {"encoder"}:  # ì§ë ¬í™” ë¶ˆê°€, ì•„í‹°íŒ©íŠ¸ë¡œ ì´ë¯¸ ì €ì¥ë¨
                    continue
                out[k] = self._sanitize_for_json(v)
            return out
        elif isinstance(obj, (list, tuple)):
            return [self._sanitize_for_json(v) for v in obj]
        elif isinstance(obj, (np.integer,)):
            return int(obj)
        elif isinstance(obj, (np.floating,)):
            return float(obj)
        elif isinstance(obj, (np.ndarray,)):
            return obj.tolist()
        elif isinstance(obj, (pd.Series,)):
            return obj.tolist()
        elif isinstance(obj, (pd.DataFrame,)):
            return obj.to_dict(orient="list")
        else:
            try:
                json.dumps(obj)
                return obj
            except Exception:
                return repr(obj)

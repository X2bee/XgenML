# /src/xgenml/core/tasks/timeseries.py
from typing import List, Tuple, Dict, Any, Optional
import pandas as pd
import numpy as np
from datetime import datetime

from .base import BaseTask
from . import TaskRegistry
from ..metrics import timeseries_metrics
from ...utils.logger_config import setup_logger

logger = setup_logger(__name__)


@TaskRegistry.register("timeseries")
class TimeSeriesTask(BaseTask):
    """ì‹œê³„ì—´ ì˜ˆì¸¡ íƒœìŠ¤í¬"""
    
    def _get_task_type(self) -> str:
        return "timeseries"
    
    def prepare_data(
    self,
    df: pd.DataFrame,
    target_column: str,
    feature_columns: Optional[List[str]] = None,
    time_column: Optional[str] = None,
    lookback_window: int = 30,
    forecast_horizon: int = 1,
    **kwargs
    ) -> Tuple[np.ndarray, np.ndarray, List[str], Dict[str, Any]]:
        """ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„"""
        self.validate_data(df, target_column)
        
        # ğŸ”¥ ìˆ˜ì • 1: ì‹œê°„ ì»¬ëŸ¼ ì²˜ë¦¬ ê°•í™”
        if time_column:
            if time_column not in df.columns:
                raise ValueError(f"time_column '{time_column}'ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤")
            
            # ë‚ ì§œ íƒ€ì… ë³€í™˜
            if df[time_column].dtype == 'object':
                try:
                    df[time_column] = pd.to_datetime(df[time_column])
                    logger.info(f"'{time_column}' ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜")
                except Exception as e:
                    logger.warning(f"ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {e}. ì›ë³¸ ë°ì´í„° ì‚¬ìš©")
            
            # ì •ë ¬ ë° ì¸ë±ìŠ¤ ë¦¬ì…‹
            df = df.sort_values(time_column).reset_index(drop=True)
            logger.info(f"ì‹œê°„ ì»¬ëŸ¼ '{time_column}'ìœ¼ë¡œ ì •ë ¬ ì™„ë£Œ")
        
        # ğŸ”¥ ìˆ˜ì • 2: í”¼ì²˜ ì„ íƒ ë¡œì§ ëª…í™•í™”
        if feature_columns:
            # ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ëœ ê²½ìš°
            feature_cols = feature_columns
            logger.info(f"ëª…ì‹œì  í”¼ì²˜ ì‚¬ìš©: {feature_cols}")
        else:
            # ìë™ ì„ íƒ: targetê³¼ time_column ì œì™¸
            exclude_cols = {target_column}
            if time_column:
                exclude_cols.add(time_column)
            
            feature_cols = [col for col in df.columns if col not in exclude_cols]
            logger.info(f"ìë™ í”¼ì²˜ ì„ íƒ: {feature_cols}")
            logger.info(f"ì œì™¸ëœ ì»¬ëŸ¼: {exclude_cols}")
        
        # ğŸ”¥ ì¶”ê°€: í”¼ì²˜ ê²€ì¦
        missing_features = set(feature_cols) - set(df.columns)
        if missing_features:
            raise ValueError(f"ë°ì´í„°ì— ì—†ëŠ” í”¼ì²˜: {missing_features}")
        
        # ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±
        X, y = self._create_sequences(
            df[feature_cols].values,
            df[target_column].values,
            lookback_window,
            forecast_horizon
        )
        
        # í”¼ì²˜ ì´ë¦„ ìƒì„±
        feature_names = []
        for lag in range(lookback_window, 0, -1):
            for col in feature_cols:
                feature_names.append(f"{col}_lag_{lag}")
        
        metadata = {
            "label_encoded": False,
            "time_column": time_column,  # ğŸ”¥ Noneì´ ì•„ë‹Œ ì‹¤ì œ ê°’ ì €ì¥
            "lookback_window": lookback_window,
            "forecast_horizon": forecast_horizon,
            "original_feature_names": feature_cols,
            "time_series_type": "univariate" if len(feature_cols) == 1 else "multivariate"
        }
        
        logger.info(f"âœ… ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±: X={X.shape}, y={y.shape}")
        logger.info(f"   Lookback: {lookback_window}, Forecast: {forecast_horizon}")
        logger.info(f"   í”¼ì²˜ ìˆ˜: {len(feature_cols)}, ì´ lag í”¼ì²˜: {len(feature_names)}")
        
        return X, y, feature_names, metadata

    
    def _create_sequences(
    self,
    features: np.ndarray,
    target: np.ndarray,
    lookback: int,
    horizon: int
    ) -> Tuple[np.ndarray, np.ndarray]:
        """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„± - 3D í˜•íƒœ ìœ ì§€"""
        X, y = [], []
        
        for i in range(len(features) - lookback - horizon + 1):
            # ğŸ”¥ ìˆ˜ì •: flatten ì œê±° â†’ 3D ìœ ì§€
            X.append(features[i:i+lookback])  # (lookback, n_features)
            
            if horizon == 1:
                y.append(target[i+lookback])
            else:
                y.append(target[i+lookback:i+lookback+horizon])
        
        X = np.array(X)  # (n_samples, lookback, n_features)
        y = np.array(y)
        
        # ğŸ”¥ ì¶”ê°€: sklearn ëª¨ë¸ìš©ìœ¼ë¡œëŠ” 2D ë³€í™˜ í•„ìš”
        # ë‚˜ì¤‘ì— ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ reshape ì„ íƒ
        X_2d = X.reshape(X.shape[0], -1)  # (n_samples, lookback*n_features)
        
    return X_2d, y  # ì¼ë‹¨ 2D ë°˜í™˜ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜)
    
    def split_data(
        self,
        X: np.ndarray,
        y: np.ndarray,
        test_size: float = 0.2,
        val_size: float = 0.1,
        random_state: int = 42,
        **kwargs
    ) -> Tuple:
        """
        ì‹œê³„ì—´ ë°ì´í„° ë¶„í•  (ì‹œê°„ ìˆœì„œ ìœ ì§€)
        âš ï¸ ì‹œê³„ì—´ì€ ëœë¤ ì…”í”Œí•˜ì§€ ì•ŠìŒ!
        """
        n_samples = len(X)
        
        # í…ŒìŠ¤íŠ¸ ë¶„í• ì 
        test_split = int(n_samples * (1 - test_size))
        X_temp, X_test = X[:test_split], X[test_split:]
        y_temp, y_test = y[:test_split], y[test_split:]
        
        logger.info(f"ì‹œê³„ì—´ ë¶„í•  (ì‹œê°„ ìˆœì„œ ìœ ì§€): Train+Val={len(X_temp)}, Test={len(X_test)}")
        
        # ê²€ì¦ ë¶„í• 
        if val_size > 0:
            val_split = int(len(X_temp) * (1 - val_size / (1 - test_size)))
            X_train, X_val = X_temp[:val_split], X_temp[val_split:]
            y_train, y_val = y_temp[:val_split], y_temp[val_split:]
            logger.info(f"Train={len(X_train)}, Val={len(X_val)}")
        else:
            X_train, X_val, y_train, y_val = X_temp, None, y_temp, None
        
        return X_train, X_val, X_test, y_train, y_val, y_test
    
    def get_default_models(self) -> List[str]:
        """ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸"""
        return [
            "random_forest",
            "gradient_boosting",
            "xgboost",
            "lightgbm",
            "linear_regression",
            # ë‚˜ì¤‘ì— ì¶”ê°€ ê°€ëŠ¥: ARIMA, Prophet, LSTM ë“±
        ]
    
    def get_primary_metric(self) -> str:
        return "rmse"
    
    def evaluate_model(
        self,
        estimator,
        X_test,
        y_test,
        **kwargs
    ) -> Dict[str, Any]:
        """ì‹œê³„ì—´ ëª¨ë¸ í‰ê°€"""
        y_pred = estimator.predict(X_test)
        return timeseries_metrics(y_test, y_pred)